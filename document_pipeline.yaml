# PIPELINE DEFINITION
# Name: document-processing-pipeline
# Description: Pipeline per processare documenti da MinIO a Qdrant con LangChain
# Inputs:
#    chunk_overlap: int [Default: 200.0]
#    chunk_size: int [Default: 1000.0]
#    collection_name: str [Default: 'documents']
#    embedding_model: str [Default: 'sentence-transformers/all-MiniLM-L6-v2']
#    hf_api_key: str [Default: '']
#    minio_access_key: str [Default: 'minio']
#    minio_bucket: str [Default: 'dvc-storage']
#    minio_endpoint: str [Default: 'minio-service.kubeflow.svc.cluster.local:9000']
#    minio_secret_key: str [Default: '']
#    qdrant_url: str [Default: 'http://qdrant:6333']
#    vector_size: int [Default: 384.0]
components:
  comp-chunk-documents:
    executorLabel: exec-chunk-documents
    inputDefinitions:
      artifacts:
        documents:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        chunk_overlap:
          parameterType: NUMBER_INTEGER
        chunk_size:
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      artifacts:
        output_chunks:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-create-embeddings:
    executorLabel: exec-create-embeddings
    inputDefinitions:
      artifacts:
        chunks:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        hf_api_key:
          parameterType: STRING
        model_name:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_embeddings:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-download-from-minio:
    executorLabel: exec-download-from-minio
    inputDefinitions:
      parameters:
        access_key:
          parameterType: STRING
        git_branch:
          parameterType: STRING
        git_repo_url:
          parameterType: STRING
        minio_endpoint:
          parameterType: STRING
        secret_key:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-upload-to-qdrant:
    executorLabel: exec-upload-to-qdrant
    inputDefinitions:
      artifacts:
        embeddings:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        collection_name:
          parameterType: STRING
        qdrant_url:
          parameterType: STRING
        vector_size:
          parameterType: NUMBER_INTEGER
deploymentSpec:
  executors:
    exec-chunk-documents:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - chunk_documents
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'langchain==0.3.0'\
          \ 'langchain-text-splitters==0.3.0'  &&  python3 -m pip install --quiet\
          \ --no-warn-script-location 'kfp==2.14.6' '--no-deps' 'typing-extensions>=3.7.4,<5;\
          \ python_version<\"3.9\"' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef chunk_documents(\n    documents: Input[Dataset],\n    chunk_size:\
          \ int,\n    chunk_overlap: int,\n    output_chunks: Output[Dataset]\n):\n\
          \    from langchain_text_splitters import RecursiveCharacterTextSplitter\n\
          \    import os\n    import json\n\n    print(f\"=== Exploring documents\
          \ path: {documents.path} ===\")\n\n    splitter = RecursiveCharacterTextSplitter(\n\
          \        chunk_size=chunk_size,\n        chunk_overlap=chunk_overlap,\n\
          \        length_function=len\n    )\n\n    all_chunks = []\n\n    for root,\
          \ dirs, files in os.walk(documents.path):\n        for file in files:\n\
          \            if file.startswith('.'):\n                continue\n\n    \
          \        file_path = os.path.join(root, file)\n            file_size = os.path.getsize(file_path)\n\
          \            print(f\"Processing: {file} ({file_size} bytes)\")\n\n    \
          \        try:\n                with open(file_path, 'r', encoding='utf-8',\
          \ errors='ignore') as f:\n                    content = f.read()\n\n   \
          \             if content.strip():\n                    chunks = splitter.split_text(content)\n\
          \n                    for i, chunk in enumerate(chunks):\n             \
          \           all_chunks.append({\n                            'source': file,\n\
          \                            'chunk_id': i,\n                          \
          \  'content': chunk\n                        })\n                    print(f\"\
          \  \u2192 Created {len(chunks)} chunks\")\n                else:\n     \
          \               print(f\"  \u2192 Empty file, skipped\")\n\n           \
          \ except Exception as e:\n                print(f\"  \u2192 Error: {e}\"\
          )\n\n    os.makedirs(output_chunks.path, exist_ok=True)\n    output_file\
          \ = os.path.join(output_chunks.path, \"chunks.json\")\n    with open(output_file,\
          \ 'w', encoding='utf-8') as f:\n        json.dump(all_chunks, f, ensure_ascii=False)\n\
          \n    output_chunks.metadata[\"chunk_count\"] = len(all_chunks)\n    print(f\"\
          \\n\u2713 Total chunks created: {len(all_chunks)}\")\n\n"
        image: python:3.10
    exec-create-embeddings:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - create_embeddings
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'huggingface-hub>=0.20.0'\
          \ 'numpy>=1.24.0'  &&  python3 -m pip install --quiet --no-warn-script-location\
          \ 'kfp==2.14.6' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"\
          3.9\"' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef create_embeddings(\n    chunks: Input[Dataset],\n    model_name:\
          \ str,\n    hf_api_key: str,\n    output_embeddings: Output[Dataset]\n):\n\
          \    from huggingface_hub import InferenceClient\n    import json\n    import\
          \ os\n\n    client = InferenceClient(token=hf_api_key)\n\n    chunks_file\
          \ = os.path.join(chunks.path, \"chunks.json\")\n    with open(chunks_file,\
          \ 'r', encoding='utf-8') as f:\n        chunks_data = json.load(f)\n\n \
          \   embedded_chunks = []\n\n    print(f\"Generazione embeddings per {len(chunks_data)}\
          \ chunks con {model_name}...\")\n\n    for i, chunk in enumerate(chunks_data):\n\
          \        embedding = client.feature_extraction(\n            text=chunk['content'],\n\
          \            model=model_name\n        )\n\n        if hasattr(embedding,\
          \ 'tolist'):\n            embedding = embedding.tolist()\n        elif isinstance(embedding,\
          \ list) and len(embedding) > 0 and hasattr(embedding[0], 'tolist'):\n  \
          \          embedding = [e.tolist() if hasattr(e, 'tolist') else e for e\
          \ in embedding][0]\n\n        embedded_chunks.append({\n            **chunk,\n\
          \            'embedding': embedding\n        })\n\n        if (i + 1) %\
          \ 10 == 0:\n            print(f\"Processati {i + 1}/{len(chunks_data)} chunks\"\
          )\n\n    os.makedirs(output_embeddings.path, exist_ok=True)\n    output_file\
          \ = os.path.join(output_embeddings.path, \"embeddings.json\")\n    with\
          \ open(output_file, 'w', encoding='utf-8') as f:\n        json.dump(embedded_chunks,\
          \ f, ensure_ascii=False)\n\n    output_embeddings.metadata[\"embedding_count\"\
          ] = len(embedded_chunks)\n    print(f\"\u2713 Embeddings completati: {len(embedded_chunks)}\
          \ chunks\")\n\n"
        image: python:3.10
    exec-download-from-minio:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - download_from_minio
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'dvc==3.48.0'\
          \ 'dvc-s3==3.2.0' 'gitpython'  &&  python3 -m pip install --quiet --no-warn-script-location\
          \ 'kfp==2.14.6' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"\
          3.9\"' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef download_from_minio(\n    git_repo_url: str,\n    git_branch:\
          \ str,\n    minio_endpoint: str,\n    access_key: str,\n    secret_key:\
          \ str,\n    output_dataset: Output[Dataset]\n):\n    import os\n    import\
          \ shutil\n    import subprocess\n\n    # Clone del repository\n    repo_dir\
          \ = \"/tmp/repo\"\n    subprocess.run([\"git\", \"clone\", \"-b\", git_branch,\
          \ git_repo_url, repo_dir], check=True)\n\n    os.chdir(repo_dir)\n\n   \
          \ # Configura credenziali MinIO per DVC\n    subprocess.run([\"dvc\", \"\
          remote\", \"modify\", \"myminio\", \"access_key_id\", access_key], check=True)\n\
          \    subprocess.run([\"dvc\", \"remote\", \"modify\", \"myminio\", \"secret_access_key\"\
          , secret_key], check=True)\n    subprocess.run([\"dvc\", \"remote\", \"\
          modify\", \"myminio\", \"endpointurl\", f\"http://{minio_endpoint}\"], check=True)\n\
          \n    # DVC pull\n    subprocess.run([\"dvc\", \"pull\"], check=True)\n\n\
          \    # Copia i documenti scaricati nell'output\n    docs_path = os.path.join(repo_dir,\
          \ \"data/documents\")\n    os.makedirs(output_dataset.path, exist_ok=True)\n\
          \n    for item in os.listdir(docs_path):\n        src = os.path.join(docs_path,\
          \ item)\n        dst = os.path.join(output_dataset.path, item)\n       \
          \ if os.path.isdir(src):\n            shutil.copytree(src, dst)\n      \
          \  else:\n            shutil.copy2(src, dst)\n\n    file_count = len([f\
          \ for f in os.listdir(output_dataset.path) if os.path.isfile(os.path.join(output_dataset.path,\
          \ f))])\n    output_dataset.metadata[\"file_count\"] = file_count\n    print(f\"\
          \u2713 DVC pull completato: {file_count} files\")\n\n"
        image: python:3.10
    exec-upload-to-qdrant:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - upload_to_qdrant
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'qdrant-client==1.7.0'\
          \  &&  python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef upload_to_qdrant(\n    embeddings: Input[Dataset],\n    qdrant_url:\
          \ str,\n    collection_name: str,\n    vector_size: int\n):\n    from qdrant_client\
          \ import QdrantClient\n    from qdrant_client.models import Distance, VectorParams,\
          \ PointStruct\n    import json\n    import uuid\n    import os\n\n    client\
          \ = QdrantClient(url=qdrant_url)\n\n    try:\n        client.create_collection(\n\
          \            collection_name=collection_name,\n            vectors_config=VectorParams(\n\
          \                size=vector_size,\n                distance=Distance.COSINE\n\
          \            )\n        )\n        print(f\"Collection '{collection_name}'\
          \ creata\")\n    except Exception as e:\n        print(f\"Collection gi\xE0\
          \ esistente o errore: {e}\")\n\n    embeddings_file = os.path.join(embeddings.path,\
          \ \"embeddings.json\")\n    with open(embeddings_file, 'r', encoding='utf-8')\
          \ as f:\n        embedded_chunks = json.load(f)\n\n    points = []\n   \
          \ for chunk in embedded_chunks:\n        point = PointStruct(\n        \
          \    id=str(uuid.uuid4()),\n            vector=chunk['embedding'],\n   \
          \         payload={\n                'source': chunk['source'],\n      \
          \          'chunk_id': chunk['chunk_id'],\n                'content': chunk['content']\n\
          \            }\n        )\n        points.append(point)\n\n    batch_size\
          \ = 100\n    for i in range(0, len(points), batch_size):\n        batch\
          \ = points[i:i+batch_size]\n        client.upsert(\n            collection_name=collection_name,\n\
          \            points=batch\n        )\n        print(f\"Uploaded batch {i//batch_size\
          \ + 1}/{(len(points)-1)//batch_size + 1}\")\n\n    print(f\"\u2713 Uploaded\
          \ {len(points)} points to Qdrant collection '{collection_name}'\")\n\n"
        image: python:3.10
pipelineInfo:
  description: Pipeline per processare documenti da MinIO a Qdrant con LangChain
  name: document-processing-pipeline
root:
  dag:
    tasks:
      chunk-documents:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-chunk-documents
        dependentTasks:
        - download-from-minio
        inputs:
          artifacts:
            documents:
              taskOutputArtifact:
                outputArtifactKey: output_dataset
                producerTask: download-from-minio
          parameters:
            chunk_overlap:
              componentInputParameter: chunk_overlap
            chunk_size:
              componentInputParameter: chunk_size
        taskInfo:
          name: chunk-documents
      create-embeddings:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-create-embeddings
        dependentTasks:
        - chunk-documents
        inputs:
          artifacts:
            chunks:
              taskOutputArtifact:
                outputArtifactKey: output_chunks
                producerTask: chunk-documents
          parameters:
            hf_api_key:
              componentInputParameter: hf_api_key
            model_name:
              componentInputParameter: embedding_model
        taskInfo:
          name: create-embeddings
      download-from-minio:
        cachingOptions: {}
        componentRef:
          name: comp-download-from-minio
        inputs:
          parameters:
            access_key:
              componentInputParameter: minio_access_key
            git_branch:
              runtimeValue:
                constant: main
            git_repo_url:
              runtimeValue:
                constant: https://github.com/vincenzo426/MLOpsRepo
            minio_endpoint:
              componentInputParameter: minio_endpoint
            secret_key:
              componentInputParameter: minio_secret_key
        taskInfo:
          name: download-from-minio
      upload-to-qdrant:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-upload-to-qdrant
        dependentTasks:
        - create-embeddings
        inputs:
          artifacts:
            embeddings:
              taskOutputArtifact:
                outputArtifactKey: output_embeddings
                producerTask: create-embeddings
          parameters:
            collection_name:
              componentInputParameter: collection_name
            qdrant_url:
              componentInputParameter: qdrant_url
            vector_size:
              componentInputParameter: vector_size
        taskInfo:
          name: upload-to-qdrant
  inputDefinitions:
    parameters:
      chunk_overlap:
        defaultValue: 200.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      chunk_size:
        defaultValue: 1000.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      collection_name:
        defaultValue: documents
        isOptional: true
        parameterType: STRING
      embedding_model:
        defaultValue: sentence-transformers/all-MiniLM-L6-v2
        isOptional: true
        parameterType: STRING
      hf_api_key:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      minio_access_key:
        defaultValue: minio
        isOptional: true
        parameterType: STRING
      minio_bucket:
        defaultValue: dvc-storage
        isOptional: true
        parameterType: STRING
      minio_endpoint:
        defaultValue: minio-service.kubeflow.svc.cluster.local:9000
        isOptional: true
        parameterType: STRING
      minio_secret_key:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      qdrant_url:
        defaultValue: http://qdrant:6333
        isOptional: true
        parameterType: STRING
      vector_size:
        defaultValue: 384.0
        isOptional: true
        parameterType: NUMBER_INTEGER
schemaVersion: 2.1.0
sdkVersion: kfp-2.14.6
