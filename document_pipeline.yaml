# PIPELINE DEFINITION
# Name: document-processing-pipeline
# Description: Pipeline per processare documenti (Git/DVC) a Qdrant
# Inputs:
#    chunk_overlap: int [Default: 200.0]
#    chunk_size: int [Default: 1000.0]
#    collection_name: str [Default: 'documents']
#    dvc_data_path: str [Default: 'data/documents']
#    dvc_remote_name: str [Default: 'myminio']
#    embedding_model: str [Default: 'sentence-transformers/all-MiniLM-L6-v2']
#    git_repo_url: str
#    hf_api_key: str [Default: '']
#    minio_access_key: str [Default: 'minio']
#    minio_endpoint: str [Default: 'minio-service.kubeflow.svc.cluster.local:9000']
#    minio_secret_key: str [Default: '']
#    new_commit_hash: str [Default: 'main']
#    old_commit_hash: str [Default: 'main']
#    qdrant_url: str [Default: 'http://qdrant:6333']
#    vector_size: int [Default: 384.0]
components:
  comp-chunk-documents:
    executorLabel: exec-chunk-documents
    inputDefinitions:
      artifacts:
        documents:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        chunk_overlap:
          parameterType: NUMBER_INTEGER
        chunk_size:
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      artifacts:
        output_chunks:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-create-embeddings:
    executorLabel: exec-create-embeddings
    inputDefinitions:
      artifacts:
        chunks:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        hf_api_key:
          parameterType: STRING
        model_name:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_embeddings:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-download-from-minio:
    executorLabel: exec-download-from-minio
    inputDefinitions:
      parameters:
        dvc_data_path_in_repo:
          parameterType: STRING
        dvc_remote_name:
          parameterType: STRING
        git_repo_url:
          parameterType: STRING
        minio_access_key:
          parameterType: STRING
        minio_endpoint:
          parameterType: STRING
        minio_secret_key:
          parameterType: STRING
        new_commit_hash:
          parameterType: STRING
        old_commit_hash:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-upload-to-qdrant:
    executorLabel: exec-upload-to-qdrant
    inputDefinitions:
      artifacts:
        embeddings:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        collection_name:
          parameterType: STRING
        qdrant_url:
          parameterType: STRING
        vector_size:
          parameterType: NUMBER_INTEGER
deploymentSpec:
  executors:
    exec-chunk-documents:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - chunk_documents
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'langchain==0.3.0'\
          \ 'langchain-text-splitters==0.3.0'  &&  python3 -m pip install --quiet\
          \ --no-warn-script-location 'kfp==2.14.6' '--no-deps' 'typing-extensions>=3.7.4,<5;\
          \ python_version<\"3.9\"' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef chunk_documents(\n    documents: Input[Dataset],\n    chunk_size:\
          \ int,\n    chunk_overlap: int,\n    output_chunks: Output[Dataset]\n):\n\
          \    from langchain_text_splitters import RecursiveCharacterTextSplitter\n\
          \    import os\n    import json\n\n    print(f\"=== Exploring documents\
          \ path: {documents.path} ===\")\n\n    splitter = RecursiveCharacterTextSplitter(\n\
          \        chunk_size=chunk_size,\n        chunk_overlap=chunk_overlap,\n\
          \        length_function=len\n    )\n\n    all_chunks = []\n\n    # Cammina\
          \ ricorsivamente nella cartella (ora gestisce la struttura .dir di DVC)\n\
          \    for root, dirs, files in os.walk(documents.path):\n        for file\
          \ in files:\n            # Ignora i file .dvc o .gitignore ecc.\n      \
          \      if file.startswith('.') or file.endswith('.dvc'):\n             \
          \   continue\n\n            file_path = os.path.join(root, file)\n\n   \
          \         # Gestisce il caso in cui DVC pu\xF2 lasciare file placeholder\n\
          \            if os.path.isdir(file_path):\n                continue\n\n\
          \            file_size = os.path.getsize(file_path)\n            print(f\"\
          Processing: {file} ({file_size} bytes)\")\n\n            try:\n        \
          \        with open(file_path, 'r', encoding='utf-8', errors='ignore') as\
          \ f:\n                    content = f.read()\n\n                if content.strip():\n\
          \                    chunks = splitter.split_text(content)\n\n         \
          \           for i, chunk in enumerate(chunks):\n                       \
          \ all_chunks.append({\n                            # Usa os.path.relpath\
          \ per un nome sorgente pulito\n                            'source': os.path.relpath(file_path,\
          \ documents.path),\n                            'chunk_id': i,\n       \
          \                     'content': chunk\n                        })\n   \
          \                 print(f\"  \u2192 Created {len(chunks)} chunks\")\n  \
          \              else:\n                    print(f\"  \u2192 Empty file,\
          \ skipped\")\n\n            except Exception as e:\n                print(f\"\
          \  \u2192 Error processing {file_path}: {e}\")\n\n    # IMPORTANTE: Gestione\
          \ del caso \"Nessun file modificato\"\n    if not all_chunks:\n        print(\"\
          \u2713 Nessun chunk creato (nessun file nuovo/modificato da processare).\"\
          )\n        # Crea un file di chunks vuoto per non far fallire il prossimo\
          \ step\n        all_chunks = []\n\n    os.makedirs(output_chunks.path, exist_ok=True)\n\
          \    output_file = os.path.join(output_chunks.path, \"chunks.json\")\n \
          \   with open(output_file, 'w', encoding='utf-8') as f:\n        json.dump(all_chunks,\
          \ f, ensure_ascii=False)\n\n    output_chunks.metadata[\"chunk_count\"]\
          \ = len(all_chunks)\n    print(f\"\\n\u2713 Total chunks created: {len(all_chunks)}\"\
          )\n\n"
        image: python:3.10
    exec-create-embeddings:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - create_embeddings
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'huggingface-hub>=0.20.0'\
          \ 'numpy>=1.24.0'  &&  python3 -m pip install --quiet --no-warn-script-location\
          \ 'kfp==2.14.6' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"\
          3.9\"' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef create_embeddings(\n    chunks: Input[Dataset],\n    model_name:\
          \ str,\n    hf_api_key: str,\n    output_embeddings: Output[Dataset]\n):\n\
          \    from huggingface_hub import InferenceClient\n    import json\n    import\
          \ os\n\n    client = InferenceClient(token=hf_api_key)\n\n    chunks_file\
          \ = os.path.join(chunks.path, \"chunks.json\")\n    with open(chunks_file,\
          \ 'r', encoding='utf-8') as f:\n        chunks_data = json.load(f)\n\n \
          \   # IMPORTANTE: Gestione del caso \"Nessun chunk\"\n    if not chunks_data:\n\
          \        print(\"\u2713 Nessun chunk da processare per l'embedding.\")\n\
          \        embedded_chunks = []\n    else:\n        embedded_chunks = []\n\
          \        print(f\"Generazione embeddings per {len(chunks_data)} chunks con\
          \ {model_name}...\")\n\n        # Logica di Batching (come prima)\n    \
          \    contents_to_embed = [chunk['content'] for chunk in chunks_data]\n \
          \       try:\n            print(f\"Tentativo di embedding in batch di {len(contents_to_embed)}\
          \ chunks...\")\n            embeddings = client.feature_extraction(\n  \
          \              text=contents_to_embed,\n                model=model_name\n\
          \            )\n            if hasattr(embeddings, 'tolist'):\n        \
          \        embeddings_list = embeddings.tolist()\n            elif isinstance(embeddings,\
          \ list):\n                embeddings_list = [e.tolist() if hasattr(e, 'tolist')\
          \ else e for e in embeddings]\n            else:\n                raise\
          \ Exception(\"Tipo di embedding non gestito\")\n            print(f\"Batch\
          \ embedding riuscito.\")\n            for i, chunk in enumerate(chunks_data):\n\
          \                embedded_chunks.append({\n                    **chunk,\n\
          \                    'embedding': embeddings_list[i]\n                })\n\
          \n        except Exception as e:\n            print(f\"Batch embedding fallito\
          \ ({e}), fallback a embedding singolo...\")\n            # (logica di fallback...\
          \ omessa per brevit\xE0)\n            pass\n\n    os.makedirs(output_embeddings.path,\
          \ exist_ok=True)\n    output_file = os.path.join(output_embeddings.path,\
          \ \"embeddings.json\")\n    with open(output_file, 'w', encoding='utf-8')\
          \ as f:\n        json.dump(embedded_chunks, f, ensure_ascii=False)\n\n \
          \   output_embeddings.metadata[\"embedding_count\"] = len(embedded_chunks)\n\
          \    print(f\"\u2713 Embeddings completati: {len(embedded_chunks)} chunks\"\
          )\n\n"
        image: python:3.10
    exec-download-from-minio:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - download_from_minio
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef download_from_minio(\n    git_repo_url: str,\n    new_commit_hash:\
          \ str,      # Il commit corrente (es. github.sha)\n    old_commit_hash:\
          \ str,      # Il commit precedente (es. github.event.before)\n    minio_endpoint:\
          \ str,\n    minio_access_key: str,     # RICEVUTO COME PARAMETRO\n    minio_secret_key:\
          \ str,     # RICEVUTO COME PARAMETRO\n    dvc_remote_name: str,\n    dvc_data_path_in_repo:\
          \ str,\n    output_dataset: Output[Dataset]\n):\n    \"\"\"\n    Componente\
          \ KFP per clonare un repo, trovare i file DVC modificati\n    tra due commit\
          \ (delta), scaricare solo quelli e passarli in output.\n    Le credenziali\
          \ MinIO sono passate come parametri (NON SICURO).\n    \"\"\"\n    import\
          \ sys\n    import subprocess\n\n    # Funzione helper per eseguire comandi\n\
          \    def run_command(command: list, return_stdout=False):\n        print(f\"\
          Esecuzione: {' '.join(command)}\")\n        try:\n            process =\
          \ subprocess.run(\n                command,\n                check=True,\n\
          \                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n\
          \                text=True,\n                encoding='utf-8'\n        \
          \    )\n            print(\"STDOUT:\", process.stdout)\n            if process.stderr:\n\
          \                print(\"STDERR:\", process.stderr)\n            if return_stdout:\n\
          \                return process.stdout\n        except subprocess.CalledProcessError\
          \ as e:\n            print(f\"Errore durante l'esecuzione di: {' '.join(e.cmd)}\"\
          )\n            print(\"STDOUT:\", e.stdout)\n            print(\"STDERR:\"\
          , e.stderr)\n            sys.exit(1)\n        except Exception as e:\n \
          \           print(f\"Errore inatteso: {e}\")\n            sys.exit(1)\n\n\
          \    # 1. Setup\n    WORKDIR = \"/app/data\"\n    os.makedirs(WORKDIR, exist_ok=True)\n\
          \    os.chdir(WORKDIR)\n    print(f\"Directory di lavoro: {os.getcwd()}\"\
          )\n    os.makedirs(output_dataset.path, exist_ok=True) # Crea subito la\
          \ dir di output\n\n    # 2. Git\n    run_command([\"git\", \"clone\", git_repo_url,\
          \ \".\"])\n    run_command([\"git\", \"checkout\", new_commit_hash])\n \
          \   print(f\"Checkout del commit {new_commit_hash} eseguito.\")\n\n    #\
          \ 3. Configurazione DVC (con credenziali passate come parametri)\n    print(\"\
          Configurazione DVC remote (con credenziali da parametri)...\")\n    run_command([\"\
          dvc\", \"remote\", \"modify\", \"--local\", dvc_remote_name, \"endpointurl\"\
          , minio_endpoint])\n    run_command([\"dvc\", \"remote\", \"modify\", \"\
          --local\", dvc_remote_name, \"access_key_id\", minio_access_key])\n    run_command([\"\
          dvc\", \"remote\", \"modify\", \"--local\", dvc_remote_name, \"secret_access_key\"\
          , minio_secret_key])\n    run_command([\"dvc\", \"remote\", \"modify\",\
          \ \"--local\", dvc_remote_name, \"use_ssl\", \"false\"])\n\n    # 4. Logica\
          \ \"Delta\" (dvc diff)\n    print(f\"Calcolo del delta tra {old_commit_hash}\
          \ e {new_commit_hash}...\")\n\n    # Assicura che anche il vecchio commit\
          \ sia \"fetchato\" per poter fare il diff\n    run_command([\"git\", \"\
          fetch\", \"origin\", old_commit_hash])\n\n    diff_output = run_command(\n\
          \        [\"dvc\", \"diff\", \"--name-only\", old_commit_hash, new_commit_hash],\n\
          \        return_stdout=True\n    )\n\n    # Filtra solo i file nel nostro\
          \ path di dati\n    all_changed_files = diff_output.splitlines() if diff_output\
          \ else []\n    files_to_pull = [\n        f for f in all_changed_files \n\
          \        if f.startswith(dvc_data_path_in_repo)\n    ]\n\n    if not files_to_pull:\n\
          \        print(\"\u2713 Nessun file di dati modificato. La pipeline non\
          \ processer\xE0 nulla.\")\n        # Non creiamo file, il prossimo step\
          \ (chunking) ricever\xE0 una dir vuota\n        return\n\n    print(f\"\
          File modificati trovati ({len(files_to_pull)}): \\n{files_to_pull}\")\n\n\
          \    # 5. Scarica *solo* i file modificati\n    print(\"Scaricamento solo\
          \ dei file modificati...\")\n    run_command([\"dvc\", \"pull\"] + files_to_pull)\n\
          \n    # 6. Copia *solo* i file modificati nell'Output[Path] di KFP\n   \
          \ # Mantenendo la loro struttura di cartelle\n    print(f\"Copia dei file\
          \ modificati in {output_dataset.path}...\")\n    copied_count = 0\n    for\
          \ file_in_repo in files_to_pull:\n        source_path = os.path.join(WORKDIR,\
          \ file_in_repo)\n\n        # Gestisce il caso in cui il diff elenchi una\
          \ cartella ma noi vogliamo i file\n        if os.path.isdir(source_path):\n\
          \            continue\n\n        # Crea la stessa struttura di cartelle\
          \ nell'output\n        relative_path = os.path.relpath(source_path, os.path.join(WORKDIR,\
          \ dvc_data_path_in_repo))\n        target_path = os.path.join(output_dataset.path,\
          \ relative_path)\n\n        os.makedirs(os.path.dirname(target_path), exist_ok=True)\n\
          \        shutil.copy(source_path, target_path)\n        copied_count +=\
          \ 1\n\n    print(f\"\u2713 Copiati {copied_count} file modificati.\")\n\n"
        image: docker.io/iterative/dvc:latest-s3
    exec-upload-to-qdrant:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - upload_to_qdrant
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'qdrant-client==1.7.0'\
          \  &&  python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef upload_to_qdrant(\n    embeddings: Input[Dataset],\n    qdrant_url:\
          \ str,\n    collection_name: str,\n    vector_size: int\n):\n    from qdrant_client\
          \ import QdrantClient\n    from qdrant_client.models import Distance, VectorParams,\
          \ PointStruct\n    import json\n    import uuid\n    import os\n    import\
          \ hashlib\n\n    client = QdrantClient(url=qdrant_url)\n\n    try:\n   \
          \     client.create_collection(\n            collection_name=collection_name,\n\
          \            vectors_config=VectorParams(\n                size=vector_size,\n\
          \                distance=Distance.COSINE\n            )\n        )\n  \
          \      print(f\"Collection '{collection_name}' creata\")\n    except Exception\
          \ as e:\n        print(f\"Collection gi\xE0 esistente o errore: {e}\")\n\
          \n    embeddings_file = os.path.join(embeddings.path, \"embeddings.json\"\
          )\n    with open(embeddings_file, 'r', encoding='utf-8') as f:\n       \
          \ embedded_chunks = json.load(f)\n\n    # IMPORTANTE: Gestione del caso\
          \ \"Nessun embedding\"\n    if not embedded_chunks:\n        print(\"\u2713\
          \ Nessun punto da caricare su Qdrant.\")\n        return\n\n    points =\
          \ []\n    for chunk in embedded_chunks:\n        # Logica ID Deterministico\
          \ (invariata, ma ora pi\xF9 importante)\n        chunk_content = chunk['content']\n\
          \        chunk_source = chunk['source']\n        namespace_uuid = uuid.NAMESPACE_DNS\n\
          \        deterministic_id = str(uuid.uuid5(namespace_uuid, chunk_source\
          \ + chunk_content))\n\n        point = PointStruct(\n            id=deterministic_id,\
          \ \n            vector=chunk['embedding'],\n            payload={\n    \
          \            'source': chunk['source'],\n                'chunk_id': chunk['chunk_id'],\n\
          \                'content': chunk['content']\n            }\n        )\n\
          \        points.append(point)\n\n    batch_size = 100\n    print(f\"Inizio\
          \ UPSERT di {len(points)} punti in Qdrant...\")\n    for i in range(0, len(points),\
          \ batch_size):\n        batch = points[i:i+batch_size]\n        client.upsert(\n\
          \            collection_name=collection_name,\n            points=batch,\n\
          \            wait=True\n        )\n        print(f\"Uploaded batch {i//batch_size\
          \ + 1}/{(len(points)-1)//batch_size + 1}\")\n\n    print(f\"\u2713 Uploaded/Updated\
          \ {len(points)} points to Qdrant collection '{collection_name}'\")\n\n"
        image: python:3.10
pipelineInfo:
  description: Pipeline per processare documenti (Git/DVC) a Qdrant
  name: document-processing-pipeline
root:
  dag:
    tasks:
      chunk-documents:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-chunk-documents
        dependentTasks:
        - download-from-minio
        inputs:
          artifacts:
            documents:
              taskOutputArtifact:
                outputArtifactKey: output_dataset
                producerTask: download-from-minio
          parameters:
            chunk_overlap:
              componentInputParameter: chunk_overlap
            chunk_size:
              componentInputParameter: chunk_size
        taskInfo:
          name: chunk-documents
      create-embeddings:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-create-embeddings
        dependentTasks:
        - chunk-documents
        inputs:
          artifacts:
            chunks:
              taskOutputArtifact:
                outputArtifactKey: output_chunks
                producerTask: chunk-documents
          parameters:
            hf_api_key:
              componentInputParameter: hf_api_key
            model_name:
              componentInputParameter: embedding_model
        taskInfo:
          name: create-embeddings
      download-from-minio:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-download-from-minio
        inputs:
          parameters:
            dvc_data_path_in_repo:
              componentInputParameter: dvc_data_path
            dvc_remote_name:
              componentInputParameter: dvc_remote_name
            git_repo_url:
              componentInputParameter: git_repo_url
            minio_access_key:
              componentInputParameter: minio_access_key
            minio_endpoint:
              componentInputParameter: minio_endpoint
            minio_secret_key:
              componentInputParameter: minio_secret_key
            new_commit_hash:
              componentInputParameter: new_commit_hash
            old_commit_hash:
              componentInputParameter: old_commit_hash
        taskInfo:
          name: download-from-minio
      upload-to-qdrant:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-upload-to-qdrant
        dependentTasks:
        - create-embeddings
        inputs:
          artifacts:
            embeddings:
              taskOutputArtifact:
                outputArtifactKey: output_embeddings
                producerTask: create-embeddings
          parameters:
            collection_name:
              componentInputParameter: collection_name
            qdrant_url:
              componentInputParameter: qdrant_url
            vector_size:
              componentInputParameter: vector_size
        taskInfo:
          name: upload-to-qdrant
  inputDefinitions:
    parameters:
      chunk_overlap:
        defaultValue: 200.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      chunk_size:
        defaultValue: 1000.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      collection_name:
        defaultValue: documents
        isOptional: true
        parameterType: STRING
      dvc_data_path:
        defaultValue: data/documents
        isOptional: true
        parameterType: STRING
      dvc_remote_name:
        defaultValue: myminio
        isOptional: true
        parameterType: STRING
      embedding_model:
        defaultValue: sentence-transformers/all-MiniLM-L6-v2
        isOptional: true
        parameterType: STRING
      git_repo_url:
        parameterType: STRING
      hf_api_key:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      minio_access_key:
        defaultValue: minio
        isOptional: true
        parameterType: STRING
      minio_endpoint:
        defaultValue: minio-service.kubeflow.svc.cluster.local:9000
        isOptional: true
        parameterType: STRING
      minio_secret_key:
        defaultValue: ''
        isOptional: true
        parameterType: STRING
      new_commit_hash:
        defaultValue: main
        isOptional: true
        parameterType: STRING
      old_commit_hash:
        defaultValue: main
        isOptional: true
        parameterType: STRING
      qdrant_url:
        defaultValue: http://qdrant:6333
        isOptional: true
        parameterType: STRING
      vector_size:
        defaultValue: 384.0
        isOptional: true
        parameterType: NUMBER_INTEGER
schemaVersion: 2.1.0
sdkVersion: kfp-2.14.6
